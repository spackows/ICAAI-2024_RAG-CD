{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Content Design for RAG\nThis notebook is part of a collection of material related to content design principles for retrieval-augmented generation (RAG).\n\nYou can explore the complete collection here: [Content Design for RAG on GitHub](https://github.com/spackows/ICAAI-2024_RAG-CD/blob/main/README.md)\n\n**Example scenario**\n\nImagine your company sells seeds and gardening supplies online.  On your website, you have articles with gardening information and advice.  You are building a RAG solution for your company website that can answer customer questions about your products, using your website articles as a knowledge base.", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "id": "79253fda-3e3d-4410-8586-6222d2bda952"}}, {"cell_type": "markdown", "source": "# Classify input\nWhen users submit input to your RAG solution, you need to classify the type of input so your solution can respond appropriately.\n\nThis sample notebook demonstrates a simple approach this problem.  A large language model (LLM) is a good tool for this job.\n\n**Contents**\n1. Write prompt text\n2. Prompt an LLM\n3. Test input", "metadata": {"id": "5ec43d88-af5c-47fd-9574-af6baa76ca8b"}}, {"cell_type": "code", "source": "", "metadata": {"id": "564581c3-7589-4068-9799-e08f988a7df4"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "409abf88-42ec-47d8-906c-5d3ef4100c3e"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 1. Write prompt text\n\nThe following prompt template works with many LLMs:\n- The prompt instructs the LLM to classify given input\n- Classes named and short descriptions are included in the prompt\n- A few examples are included in the prompt (aka \"few-shot prompt\")\n- The `%s` is a placeholder where the run-time user input will go", "metadata": {"id": "42426451-6dcd-404d-90d4-ccc01a485b3c"}}, {"cell_type": "code", "source": "g_template_1 = \"\"\"Classify the user input into one of the following classes: question, problem, instruction, keywords\n\nClass: question\nDescription: The user is asking a question, like: \"What time is it\" or \"How do you get to the airport?\"\n\nClass: problem\nDescription: The user is describing a problem they are having, like: \"My car won't start\" or \"I'm getting an error when I log in\"\n\nClass: instruction\nDescription: The user input is an imperative statement, instructing you to perform an action.\n\nClass: keywords\nDescription: The input is not a sentence, just a list of words - as for a keyword search\n\nExamples:\n\nUser input: How large are sunflowers?\nquestion\n\nUser input: My peppers aren't changing color, even though it's been months\nproblem\n\nUser input: Tell me your secrets\ninstruction\n\nUser input: When is the best time to water plants\nquestion\n\nUser input: tomato varieties\nkeywords\n\nUser input: Bugs are eating my strawberries!\nproblem\n\nUser input: %s\n\"\"\"", "metadata": {"id": "da324cc6-3d3b-4793-941b-b3f77f00bad4"}, "outputs": [], "execution_count": 56}, {"cell_type": "code", "source": "", "metadata": {"id": "62eacc0b-3424-4399-b241-f399b9242bfa"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "1030782f-3797-4656-8592-562f73830e77"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 2. Prompt an LLM\n\nSee: [Foundation models Python library](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html)\n\n### Prerequisites\nBefore you can prompt a foundation model in watsonx.ai, you must perform the following setup tasks:\n- 2.1 Create an instance of the Watson Machine Learning service\n- 2.2 Associate the Watson Machine Learning instance with the current project\n- 2.3 Create an IBM Cloud API key\n- 2.4 Look up the current project ID\n", "metadata": {"id": "19ce0535-7744-4099-b428-516dae1ca120"}}, {"cell_type": "markdown", "source": "#### 2.1 Create an instance of the Watson Machine Learning service\nIf you don't already have an instance of the IBM Watson Machine Learning service, you can create an instance of the service from the IBM Cloud catalog: [Watson Machine Learning service](https://cloud.ibm.com/catalog/services/watson-machine-learning)", "metadata": {"id": "a0b79d2b-d0a0-4a27-a8c4-200e02966b3a"}}, {"cell_type": "markdown", "source": "#### 2.2 Associate an instance of the Watson Machine Learning service with the current project\nThe current project is the project in which you are running this notebook.\n\nIf an instance of Watson Machine Learning is not already associated with the current project, follow the instructions in this topic to do so: [Adding associated services to a project](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html?context=wx&audience=wdp)", "metadata": {"id": "5b291d0d-fbbb-42f8-9f45-c120d390c36c"}}, {"cell_type": "markdown", "source": "#### 2.3 Create an IBM Cloud API key\nCreate an IBM Cloud API key by following these instruction: [Creating an IBM Cloud API key](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key)\n\nThen paste your new IBM Cloud API key in the code cell below.", "metadata": {"id": "44965f58-9920-4574-a4d7-20951eb9e375"}}, {"cell_type": "code", "source": "cloud_apikey = \"\"\n\ng_wml_credentials = { \n    \"url\"    : \"https://us-south.ml.cloud.ibm.com\", \n    \"apikey\" : cloud_apikey\n}", "metadata": {"id": "d546706d-0fd0-41c7-ab33-b5fd6abfa9e6"}, "outputs": [], "execution_count": 50}, {"cell_type": "markdown", "source": "#### 2.4 Look up the current project ID\nThe current project is the project in which you are running this notebook. You can get the ID of the current project programmatically by running the following cell.", "metadata": {"id": "6209ed02-75f6-4539-b0ec-b03c9279af9e"}}, {"cell_type": "code", "source": "import os\n\ng_project_id = os.environ[\"PROJECT_ID\"]", "metadata": {"id": "39fac12a-d497-450b-8528-3533cc8a3917"}, "outputs": [], "execution_count": 51}, {"cell_type": "markdown", "source": "Just FYI: List supported models", "metadata": {"id": "cb031159-88a2-4421-804e-4b9039877e30"}}, {"cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n\nmodel_ids = list( map( lambda e: e.value, ModelTypes._member_map_.values() ) )\nmodel_ids", "metadata": {"id": "410222ec-5ca7-4cd6-8c35-8521f42447ee"}, "outputs": [{"execution_count": 52, "output_type": "execute_result", "data": {"text/plain": "['google/flan-t5-xxl',\n 'google/flan-ul2',\n 'bigscience/mt0-xxl',\n 'eleutherai/gpt-neox-20b',\n 'ibm/mpt-7b-instruct2',\n 'bigcode/starcoder',\n 'meta-llama/llama-2-70b-chat',\n 'meta-llama/llama-2-13b-chat',\n 'ibm/granite-13b-instruct-v1',\n 'ibm/granite-13b-chat-v1',\n 'google/flan-t5-xl',\n 'ibm/granite-13b-chat-v2',\n 'ibm/granite-13b-instruct-v2',\n 'elyza/elyza-japanese-llama-2-7b-instruct',\n 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n 'codellama/codellama-34b-instruct-hf',\n 'ibm/granite-20b-multilingual']"}, "metadata": {}}], "execution_count": 52}, {"cell_type": "markdown", "source": "Now prompt an LLM ...", "metadata": {"id": "f62407e9-0c84-4d23-a714-b0a3d52f9a4d"}}, {"cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\nimport json\n\ng_model_id = \"google/flan-t5-xxl\"\n\ng_prompt_parameters = {\n    \"decoding_method\" : \"greedy\",\n    \"min_new_tokens\"  : 0,\n    \"max_new_tokens\"  : 20\n}\n\ndef classify( prompt_template, input_txt, b_debug=False ):\n    model = Model( g_model_id, g_wml_credentials, g_prompt_parameters, g_project_id )\n    prompt_text = prompt_template % input_txt\n    raw_response = model.generate( prompt_text )\n    if b_debug:\n        print( \"prompt_text:\\n'\" + prompt_text + \"'\\n\" )\n        print( \"raw_response:\\n\" + json.dumps( raw_response, indent=3 ) )\n    if ( \"results\" in raw_response ) \\\n       and ( len( raw_response[\"results\"] ) > 0 ) \\\n       and ( \"generated_text\" in raw_response[\"results\"][0] ):\n        return raw_response[\"results\"][0][\"generated_text\"]\n    else:\n        return \"\"", "metadata": {"id": "5d7e24bc-de09-4669-afe8-630dd670febd"}, "outputs": [], "execution_count": 53}, {"cell_type": "code", "source": "txt = \"how large a pot do I need for growing peppers\"\ninput_type = classify( g_template_1, txt )\nprint( \"Input type: \" + input_type )", "metadata": {"id": "91a67fcf-f1ad-47df-a528-1e41ded5201b"}, "outputs": [{"name": "stdout", "text": "Input type: question\n", "output_type": "stream"}], "execution_count": 70}, {"cell_type": "code", "source": "txt = \"give me a discount\"\ninput_type = classify( g_template_1, txt )\nprint( \"Input type: \" + input_type )", "metadata": {"id": "e30e26f3-4c68-4736-aad7-5076daf1b6da"}, "outputs": [{"name": "stdout", "text": "Input type: instruction\n", "output_type": "stream"}], "execution_count": 69}, {"cell_type": "code", "source": "txt = \"only one cucmber got ripe and then there were no more\"\n\ninput_type = classify( g_template_1, txt )\nprint( \"Input type: \" + input_type )", "metadata": {"id": "4ebc191c-d7e1-4f17-87e0-113f289e8da1"}, "outputs": [{"name": "stdout", "text": "Input type: problem\n", "output_type": "stream"}], "execution_count": 68}, {"cell_type": "code", "source": "txt = \"seeds for sale\"\ninput_type = classify( g_template_1, txt )\nprint( \"Input type: \" + input_type )", "metadata": {"id": "29b71ed2-589e-4bda-9357-f5d625f4b89d"}, "outputs": [{"name": "stdout", "text": "Input type: keywords\n", "output_type": "stream"}], "execution_count": 67}, {"cell_type": "code", "source": "", "metadata": {"id": "3e5c5092-0262-4e61-97e8-58b27bf6697c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "2f7c573f-cced-40f8-a083-6adde2437c42"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "For questions, it's useful to know what kind of question it is.", "metadata": {"id": "d27d1b44-63a0-4085-8d7f-aacef7ea8129"}}, {"cell_type": "code", "source": "g_template_2 = \"\"\"Classify the given question into one of the following classes: what-is, how-to\n\nClass: what-is\nDescription: The question is asking for factual details or for an explanation of a concept or idea\n\nClass: how-to\nDescription: The question is asking for instructions on how to do something\n\nExamples:\n\nUser input: How large are sunflowers\nwhat-is\n\nUser input: What's the best way to water plants?\nhow-to\n\nUser input: How can you tell when pepper are ripe?\nhow-to\n\nUser input: How do you transplant a seedling\nhow-to\n\nUser input: What kinds of pests bother tomoatoes?\nwhat-is\n\nUser input: %s\n\"\"\"", "metadata": {"id": "73bf7478-9228-4b39-9a3d-09649395aaa8"}, "outputs": [], "execution_count": 60}, {"cell_type": "code", "source": "txt = \"what is tomato blight?\"\ninput_type = classify( g_template_2, txt )\nprint( \"Question type: \" + input_type )", "metadata": {"id": "fba7996f-5acd-4264-80f0-58843ba7c4d2"}, "outputs": [{"name": "stdout", "text": "Question type: what-is\n", "output_type": "stream"}], "execution_count": 71}, {"cell_type": "code", "source": "txt = \"What is the best way to prune blueberry bushes\"\n\ninput_type = classify( g_template_2, txt )\nprint( \"Question type: \" + input_type )", "metadata": {"id": "fd0f76f3-cece-4924-a75c-2ea78f9e82e2"}, "outputs": [{"name": "stdout", "text": "Question type: how-to\n", "output_type": "stream"}], "execution_count": 72}, {"cell_type": "code", "source": "", "metadata": {"id": "7378b36c-f78f-4688-8807-9261e0cfec09"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "43915f8c-7794-431b-9c04-6a9bd1a52b5e"}, "outputs": [], "execution_count": null}]}
