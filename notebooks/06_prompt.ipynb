{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Content Design for RAG\nThis notebook is part of a collection of material related to content design principles for retrieval-augmented generation (RAG).\n\nYou can explore the complete collection here: [Content Design for RAG on GitHub](https://github.com/spackows/ICAAI-2024_RAG-CD/blob/main/README.md)\n\n**Example scenario**\n\nImagine your company sells seeds and gardening supplies online.  On your website, you have articles with gardening information and advice.  You are building a RAG solution for your company website that can answer customer questions about your products, using your website articles as a knowledge base.", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "id": "79253fda-3e3d-4410-8586-6222d2bda952"}}, {"cell_type": "markdown", "source": "# Prompt by question type\nTo achieve best results, you can design your RAG solution to handle each type of submitted question differently.\n\nThis sample notebook demonstrates a simple approach this problem: using a distinct LLM prompt for each question type.\n\n**Contents**\n1. Write prompt text\n2. Prompt an LLM\n3. Test input", "metadata": {"id": "5ec43d88-af5c-47fd-9574-af6baa76ca8b"}}, {"cell_type": "code", "source": "", "metadata": {"id": "cfae80a4-883e-4bf8-be16-22bd9d715bab"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "5b610d05-f641-4d3f-b26e-52d7d9d4f121"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 1. Write prompt text\n\nThe following prompt templates handle two types of questions:\n- \"what-is\" questions asking for factual details or for an explanation of a concept or idea\n- \"how-to\" questions asking for instructions on how to do something", "metadata": {"id": "42426451-6dcd-404d-90d4-ccc01a485b3c"}}, {"cell_type": "code", "source": "g_whatis_template = \"\"\"Article: \n----\n%s\n----\n\nAnswer the following question using only information from the article. \nIf there is no good answer in the article, say: \"No answer was found\" \n\nQuestion: %s\nAnswer: \"\"\"", "metadata": {"id": "da324cc6-3d3b-4793-941b-b3f77f00bad4"}, "outputs": [], "execution_count": 17}, {"cell_type": "code", "source": "g_howto_template = \"\"\"Article: \n----\n%s\n----\n\nAnswer the following question as a list of numbered steps using only information from the article. \nIf there is no good answer in the article, say: \"No answer was found\"\n\nQuestion: What is the best way to water cucumbers?\nAnswer: To water cucumbers, perform these steps: \n1. Apply water to the base of the plant, to avoid fungal diseases on damp foliage\n2. Water frequently, preferably with a drip or soaker hose\n3. Avoid allowing soil to completely dry out\n4. Use mulch to keep soil moist\n\nQuestion: How do you prevent slugs eating holes in peppers\nAnswer: To prevent slugs eating holes in peppers, perform these steps: \n1. Surround your plant with a copper barrier (eg. tape)\n2. Place jagged material such as crushed eggshells or seashells around your plant\n3. Manually remove slugs in the evening or early morning\n\nQuestion: how to transpant a seedling tomato?\nAnswer: To transpant a seedling tomato, perform these steps: \n1. Harden off the seedlings to avoid transplant shock\n2. Prune flowers to send energy to growing roots\n3. Pre-moisten the soil\n4. Plant seedlings on an angle or deep enough to burying the lowest few stems\n5. Water thoroughly\n\nQuestion: %s \nAnswer: \"\"\"", "metadata": {"id": "62eacc0b-3424-4399-b241-f399b9242bfa"}, "outputs": [], "execution_count": 56}, {"cell_type": "code", "source": "", "metadata": {"id": "1030782f-3797-4656-8592-562f73830e77"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "0722c315-a6f1-4c08-9b50-b5e1cfb7a704"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 2. Prompt an LLM\n\nSee: [Foundation models Python library](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html)\n\n### Prerequisites\nBefore you can prompt a foundation model in watsonx.ai, you must perform the following setup tasks:\n- 2.1 Create an instance of the Watson Machine Learning service\n- 2.2 Associate the Watson Machine Learning instance with the current project\n- 2.3 Create an IBM Cloud API key\n- 2.4 Look up the current project ID\n", "metadata": {"id": "19ce0535-7744-4099-b428-516dae1ca120"}}, {"cell_type": "markdown", "source": "#### 2.1 Create an instance of the Watson Machine Learning service\nIf you don't already have an instance of the IBM Watson Machine Learning service, you can create an instance of the service from the IBM Cloud catalog: [Watson Machine Learning service](https://cloud.ibm.com/catalog/services/watson-machine-learning)", "metadata": {"id": "a0b79d2b-d0a0-4a27-a8c4-200e02966b3a"}}, {"cell_type": "markdown", "source": "#### 2.2 Associate an instance of the Watson Machine Learning service with the current project\nThe current project is the project in which you are running this notebook.\n\nIf an instance of Watson Machine Learning is not already associated with the current project, follow the instructions in this topic to do so: [Adding associated services to a project](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html?context=wx&audience=wdp)", "metadata": {"id": "5b291d0d-fbbb-42f8-9f45-c120d390c36c"}}, {"cell_type": "markdown", "source": "#### 2.3 Create an IBM Cloud API key\nCreate an IBM Cloud API key by following these instruction: [Creating an IBM Cloud API key](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key)\n\nThen paste your new IBM Cloud API key in the code cell below.", "metadata": {"id": "44965f58-9920-4574-a4d7-20951eb9e375"}}, {"cell_type": "code", "source": "cloud_apikey = \"\"\n\ng_wml_credentials = { \n    \"url\"    : \"https://us-south.ml.cloud.ibm.com\", \n    \"apikey\" : cloud_apikey\n}", "metadata": {"id": "d546706d-0fd0-41c7-ab33-b5fd6abfa9e6"}, "outputs": [], "execution_count": 7}, {"cell_type": "markdown", "source": "#### 2.4 Look up the current project ID\nThe current project is the project in which you are running this notebook. You can get the ID of the current project programmatically by running the following cell.", "metadata": {"id": "6209ed02-75f6-4539-b0ec-b03c9279af9e"}}, {"cell_type": "code", "source": "import os\n\ng_project_id = os.environ[\"PROJECT_ID\"]", "metadata": {"id": "39fac12a-d497-450b-8528-3533cc8a3917"}, "outputs": [], "execution_count": 8}, {"cell_type": "markdown", "source": "Just FYI: List supported models", "metadata": {"id": "cb031159-88a2-4421-804e-4b9039877e30"}}, {"cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n\nmodel_ids = list( map( lambda e: e.value, ModelTypes._member_map_.values() ) )\nmodel_ids", "metadata": {"id": "410222ec-5ca7-4cd6-8c35-8521f42447ee"}, "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "['google/flan-t5-xxl',\n 'google/flan-ul2',\n 'bigscience/mt0-xxl',\n 'eleutherai/gpt-neox-20b',\n 'ibm/mpt-7b-instruct2',\n 'bigcode/starcoder',\n 'meta-llama/llama-2-70b-chat',\n 'meta-llama/llama-2-13b-chat',\n 'ibm/granite-13b-instruct-v1',\n 'ibm/granite-13b-chat-v1',\n 'google/flan-t5-xl',\n 'ibm/granite-13b-chat-v2',\n 'ibm/granite-13b-instruct-v2',\n 'elyza/elyza-japanese-llama-2-7b-instruct',\n 'ibm-mistralai/mixtral-8x7b-instruct-v01-q',\n 'codellama/codellama-34b-instruct-hf',\n 'ibm/granite-20b-multilingual']"}, "metadata": {}}], "execution_count": 9}, {"cell_type": "markdown", "source": "Now prompt an LLM ...", "metadata": {"id": "f62407e9-0c84-4d23-a714-b0a3d52f9a4d"}}, {"cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\nimport json\n\ndef answer( model_id, prompt_parameters, prompt_template, article_txt, question_txt, b_debug=False ):\n    model = Model( model_id, g_wml_credentials, prompt_parameters, g_project_id )\n    prompt_text = prompt_template % ( article_txt, question_txt )\n    raw_response = model.generate( prompt_text )\n    if b_debug:\n        print( \"prompt_text:\\n'\" + prompt_text + \"'\\n\" )\n        print( \"raw_response:\\n\" + json.dumps( raw_response, indent=3 ) )\n    if ( \"results\" in raw_response ) \\\n       and ( len( raw_response[\"results\"] ) > 0 ) \\\n       and ( \"generated_text\" in raw_response[\"results\"][0] ):\n        return raw_response[\"results\"][0][\"generated_text\"]\n    else:\n        return \"\"", "metadata": {"id": "5d7e24bc-de09-4669-afe8-630dd670febd"}, "outputs": [], "execution_count": 34}, {"cell_type": "code", "source": "model_id = \"google/flan-t5-xxl\"\n\nprompt_parameters = {\n    \"decoding_method\" : \"sample\",\n    \"min_new_tokens\"  : 0,\n    \"max_new_tokens\"  : 300,\n    \"random_seed\"     : 2391547291\n}\n\narticle_txt = \"\"\"\n## Growing peppers in containers\nWhen it comes to growing green peppers in containers, the more room the plants have, the better.\nPepper plants need 18 - 24 inches of width, and their roots need 14 to 24 inches of depth.\nThe type of container doesn't matter: clay or plastic pots, wooden boxes, plastic totes, fabric grow bags, or even garbage bins.\n\"\"\"\nquestion_txt = \"how large a pot do I need for growing peppers\"\n\nanswer_txt = answer( model_id, prompt_parameters, g_whatis_template, article_txt, question_txt )\nprint( \"\\\"What-is\\\" question:\\n\" + question_txt + \"\\n\\nAnswer:\\n\" + answer_txt.strip() + \"\\n\" )", "metadata": {"id": "91a67fcf-f1ad-47df-a528-1e41ded5201b"}, "outputs": [{"name": "stdout", "text": "\"What-is\" question:\nhow large a pot do I need for growing peppers\n\nAnswer:\nPepper plants need 18 - 24 inches of width, and their roots need 14 to 24 inches of depth\n\n", "output_type": "stream"}], "execution_count": 68}, {"cell_type": "code", "source": "model_id = \"meta-llama/llama-2-70b-chat\"\n\nprompt_parameters = {\n    \"decoding_method\" : \"sample\",\n    \"min_new_tokens\"  : 0,\n    \"max_new_tokens\"  : 300,\n    \"stop_sequences\"  : [ \"\\n\\n\" ],\n    \"random_seed\"     : 3500937994\n}\n\narticle_txt = \"\"\"\nThere are multiple ways to harvest spinach.\nOnce there are multiple leaves and the plant is more than 4 inches tall, you can begin harvesting.\nOne option is to cut mature leaves on the outside of the plant with scissors.  This way, you can harvest continuously.\nTo harvest in bulk, gather the plant in one hand and cut the plant with a knife above the crown.  More leaves will be ready to harvest in a few weeks.\nLater in the season, when the temperature is warmer, the plant will bolt or go to seed.  The taste of the leaves changes then, so you should harvest the whole plant as soon as you see signs it is bolting.\n\"\"\"\nquestion_txt = \"How can I harvest spinach?\"\nanswer_txt = answer( model_id, prompt_parameters, g_howto_template, article_txt, question_txt )\nprint( \"\\\"How-to\\\" question:\\n\" + question_txt + \"\\n\\nAnswer:\\n\" + answer_txt.strip() + \"\\n\" )", "metadata": {"id": "e30e26f3-4c68-4736-aad7-5076daf1b6da"}, "outputs": [{"name": "stdout", "text": "\"How-to\" question:\nHow can I harvest spinach?\n\nAnswer:\n1. Cut mature leaves on the outside of the plant with scissors. \n2. Gather the plant in one hand and cut the plant with a knife above the crown. \n3. If the plant has bolted, harvest the whole plant.\n\n", "output_type": "stream"}], "execution_count": 69}, {"cell_type": "code", "source": "", "metadata": {"id": "3e5c5092-0262-4e61-97e8-58b27bf6697c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "2f7c573f-cced-40f8-a083-6adde2437c42"}, "outputs": [], "execution_count": null}]}
