{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Content Design for RAG\nThis notebook is part of a collection of material related to content design principles for retrieval-augmented generation (RAG).\n\nYou can explore the complete collection here: [Content Design for RAG on GitHub](https://github.com/spackows/RAG-CD/blob/main/README.md)", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "id": "da64f43a-876b-4746-85ed-5f56d5e00cdf"}}, {"cell_type": "markdown", "source": "## HTML to text\nThe sample code below demonstrates a simple method for converting HTML to a ~text format.  \n\nThe text format has some Markdown elements:\n- Headings (eg. #, ##, ###)\n- Ordered lists\n- Unordered lists\n- Tables converted to lists of lists\n\n**Contents**\n1. Download sample HTML files\n2. Convert HTML to text", "metadata": {"id": "2127c41b-1de7-415a-90f7-3df4673be705"}}, {"cell_type": "markdown", "source": "### 1. Download sample HTML files\n\nThe sample html files below are from the [Natural Questions](https://ai.google.com/research/NaturalQuestions) data set and benchmark.", "metadata": {"id": "fa527480-50e7-424d-a4f7-c7c3e1ce5806"}}, {"cell_type": "code", "source": "file_names_arr = [\n\"Abundance-of-elements-in-Earths-crust.html\",\n\"Atmosphere-of-Earth.html\",\n\"Axial-precession.html\",\n\"Axial-tilt.html\",\n\"Carbon-cycle.html\",\n\"Carbon-dioxide-in-Earths-atmosphere.html\",\n\"Continent.html\",\n\"Crust-geology.html\",\n\"Earth.html\",\n\"Earths-energy-budget.html\",\n\"Earths-internal-heat-budget.html\",\n\"Earths-magnetic-field.html\",\n\"Earths-orbit.html\",\n\"Earths-rotation.html\",\n\"Inner-core.html\",\n\"Mantle-geology.html\",\n\"Mantle-convection.html\",\n\"Plate-tectonics.html\",\n\"Structure-of-the-Earth.html\"\n]", "metadata": {"id": "79e621a4-875a-4271-be38-8e810c406d07"}, "outputs": [], "execution_count": 2}, {"cell_type": "code", "source": "url_base = \"https://raw.githubusercontent.com/spackows/RAG-CD/main/Natural-Questions/html/\"", "metadata": {"id": "7fa609dc-0323-4856-9ffa-58e2be8db748"}, "outputs": [], "execution_count": 3}, {"cell_type": "code", "source": "!pip install wget", "metadata": {"id": "f5a03319-9be7-4496-ae49-4bc70c1c65e8"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "import os\nimport wget\n\nfor file_name in file_names_arr:\n    url = url_base + file_name\n    if not os.path.isfile( file_name ):\n        wget.download( url, out = file_name )\n        \n!ls", "metadata": {"id": "47793a7b-c788-430d-be86-f490a5f80f0a"}, "outputs": [{"name": "stdout", "text": "Abundance-of-elements-in-Earths-crust.html  Earths-internal-heat-budget.html\nAtmosphere-of-Earth.html\t\t    Earths-magnetic-field.html\nAxial-precession.html\t\t\t    Earths-orbit.html\nAxial-tilt.html\t\t\t\t    Earths-rotation.html\nCarbon-cycle.html\t\t\t    Inner-core.html\nCarbon-dioxide-in-Earths-atmosphere.html    Mantle-convection.html\nContinent.html\t\t\t\t    Mantle-geology.html\nCrust-geology.html\t\t\t    Plate-tectonics.html\nEarth.html\t\t\t\t    Structure-of-the-Earth.html\nEarths-energy-budget.html\n", "output_type": "stream"}], "execution_count": 5}, {"cell_type": "code", "source": "", "metadata": {"id": "3542e60b-bd6e-47e1-a956-4e3a08b00892"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "7fc5dbc0-66fa-4b0e-8a84-6af4d6630b2b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from bs4 import BeautifulSoup\nimport re\nimport math\n\n\ndef removeCitation( txt ):\n    txt_out = re.sub( r\"\\[\\d+\\]\", \" \", txt )\n    txt_out = re.sub( r\"\\s+\", \" \", txt_out ).strip()\n    return txt_out\n\ndef removeUnwantedDivs( soup ):\n    nav_arr = soup.find_all( \"div\", { \"role\" : \"navigation\" } )\n    for nav in nav_arr:\n        nav.decompose()\n    nav_arr = soup.find_all( \"div\", { \"class\" : \"navbar\" } )\n    for nav in nav_arr:\n        nav.decompose()\n    toc_arr = soup.find_all( \"div\", { \"class\" : \"toc\" } )\n    for toc in toc_arr:\n        toc.decompose()\n    edit_arr = soup.find_all( \"span\", { \"class\" : \"mw-editsection\" } )\n    for edit in edit_arr:\n        edit.decompose()\n    show_arr = soup.find_all( \"span\", { \"class\" : \"collapseButton\" } )\n    for show in show_arr:\n        show.decompose()\n    access_arr = soup.find_all( \"span\", { \"class\" : \"cite-accessibility-label\" } )\n    for label in access_arr:\n        label.decompose()\n    sortkey_arr = soup.find_all( \"span\", { \"class\" : \"sortkey\" } )\n    for span in sortkey_arr:\n        span.decompose()\n\ndef processH( obj_txt, obj_name ):\n    txt = \"\"\n    if( re.match( r\"\\S\", obj_txt ) ):\n        num_str = re.sub( r\"[^\\d]\", \"\", obj_name )\n        if( re.match( r\"\\S\", num_str ) ):\n            num = int( num_str )\n            obj_txt = \"#\" * num + \" \" + obj_txt\n        txt += \"\\n\\n\" + obj_txt\n    return txt\n\ndef processP( obj_txt ):\n    txt = \"\"\n    if( re.match( r\"\\S\", obj_txt ) ):\n        txt += \"\\n\\n\" + obj_txt\n    return txt\n\ndef processOL( obj ):\n    txt = \"\"\n    count = 1\n    for li in obj.children:\n        li_txt = re.sub( r\"\\s+\", \" \", li.get_text() ).strip()\n        li_txt = removeCitation( li_txt )\n        if( re.match( r\"\\S\", li_txt ) ):\n            txt += \"\\n\" + str( count ) + \". \" + li_txt\n            count += 1\n    return txt\n\ndef processUL( obj ):\n    txt = \"\"\n    for li in obj.children:\n        li_txt = re.sub( r\"\\s+\", \" \", li.get_text() ).strip()\n        li_txt = removeCitation( li_txt )\n        if( re.match( r\"\\S\", li_txt ) ):\n            txt += \"\\n- \" + li_txt\n    return txt\n\ndef processDL( obj ):\n    txt = \"\"\n    for d_item in obj.children:\n        if( \"dt\" == d_item.name ):\n            dt_txt = re.sub( r\"\\s+\", \" \", d_item.get_text() ).strip()\n            if( re.match( r\"\\S\", dt_txt ) ):\n                txt += \"\\n\" + dt_txt + \":\"\n        else:\n            dd_txt = re.sub( r\"\\s+\", \" \", d_item.get_text() ).strip()\n            if( re.match( r\"\\S\", dd_txt ) ):\n                txt += \"\\n\" + dd_txt\n    return txt\n    \ndef convertTableToLists( table ):\n    # caption\n    caption_txt = \"\"\n    caption_obj = table.find( \"caption\" )\n    caption_txt = re.sub( r\"\\s+\", \" \", caption_obj.get_text() ).strip() if caption_obj else \"\"\n    caption_txt = removeCitation( caption_txt )\n    rows = table.find_all( \"tr\" )\n    # Headers\n    col_headings = []\n    for row in rows:\n        th_arr = row.find_all( \"th\" )\n        td_arr = row.find_all( \"td\" )\n        if( ( len( col_headings ) > 0 ) and \\\n            ( ( len( th_arr ) < 1 ) or ( len( td_arr ) > 0 ) ) ):\n            break\n        this_row_headings = []\n        for th in th_arr:\n            th_txt = re.sub( r\"\\s+\", \" \", th.get_text() ).strip() if th.get_text() else \"\"\n            th_txt = removeCitation( th_txt )\n            num_cols = math.floor( float( th[\"colspan\"] ) ) if th.has_attr( \"colspan\" ) else 1\n            this_row_headings += [ th_txt ] * num_cols\n        for i in range ( len( this_row_headings ) ):\n            if( len( col_headings ) <= i ):\n                col_headings.append( this_row_headings[i] )\n                continue\n            if( re.match( r\"\\S\", this_row_headings[i] ) ):\n                col_headings[i] = col_headings[i] + \", \" + this_row_headings[i]\n    # Make lists\n    row_lists = []\n    for row in rows:\n        td_arr = row.find_all( \"td\" )\n        if( len( td_arr ) < 1 ):\n            continue\n        list_txt = \"\"\n        col_num = 0\n        cols_arr = row.find_all( [ \"th\", \"td\" ] )\n        for col in cols_arr:\n            header_txt = col_headings[ col_num ] if ( col_num < len( col_headings ) ) else \"\"\n            col_num += 1\n            col_txt = re.sub( r\"\\s+\", \" \", col.get_text() ).strip() if col.get_text() else \"\"\n            col_txt = removeCitation( col_txt )\n            if( col_txt ):\n                list_txt += \"\\n- \" + header_txt + \": \" + col_txt\n        if( list_txt ):\n            row_lists.append( list_txt )\n    txt = \"\"\n    if( caption_txt ):\n        txt += \"\\n\\n\" + caption_txt + \":\"\n    if( len( row_lists ) > 0 ):\n        txt += \"\\n\" + \"\\n\".join( row_lists ) + \"\\n\"\n    return txt\n    \ndef HTMLToText( file_names_arr, b_debug=False ):\n    \n    for file_name in file_names_arr:\n        \n        print( file_name + \"...\" )\n        \n        f = open( file_name, \"r\" )\n        html = f.read()\n        f.close()\n\n        if b_debug:\n            print( \"\\nHTML:\\n\" + html )\n            \n        soup = BeautifulSoup( html, \"html.parser\" )\n        removeUnwantedDivs( soup )\n        txt = \"\"\n        for obj in soup.find_all( [ \"h1\", \"h2\", \"h3\", \"h4\", \"p\", \"ol\", \"ul\", \"dl\", \"table\"] ):\n            obj_name = re.sub( r\"\\s+\", \" \", obj.name ).strip().lower() if obj.name else \"\"\n            class_names_arr = obj[\"class\"] if obj.has_attr(\"class\") else []\n            obj_txt = re.sub( r\"\\s+\", \" \", obj.get_text() ).strip() if obj.get_text() else \"\"\n            obj_txt = removeCitation( obj_txt )\n            if( \"references\" == obj_txt.lower() ) or \\\n              ( \"see also\" == obj_txt.lower() ):\n                break\n            if( \"ambox\" in class_names_arr ) or \\\n              ( obj.parent and obj.parent.has_attr(\"class\") and ( \"toctitle\" in obj.parent[\"class\"] ) ):\n                continue\n            if( re.match( r\"^h\\d$\", obj_name ) ):\n                txt += processH( obj_txt, obj_name )\n                continue\n            if( \"p\" == obj_name ):\n                txt += processP( obj_txt )\n                continue\n            if( \"ol\" == obj_name ):\n                txt += processOL( obj )\n                continue\n            if( \"ul\" == obj_name ):\n                txt += processUL( obj )\n                continue\n            if( \"dl\" == obj_name ):\n                txt += processDL( obj )\n                continue\n            if( \"table\" == obj_name ):\n                txt += convertTableToLists( obj )\n                continue\n            if( obj.name and obj.get_text() ):\n                print( \"\\n\\nUNKNOWN: '\" + obj_name + \"'\\t (\" + str( class_name ) + \") '\" + obj_txt[0:100] + \"'\" )\n        \n        if b_debug:\n            print( \"\\nText:\\n\" + txt )\n            \n        file_name_out = re.sub( r\"\\.html$\", \".org.txt\", file_name )\n        f = open( file_name_out, \"w\" )\n        f.write( txt )\n        f.close()", "metadata": {"id": "9877e5c0-c30b-4e05-9393-50e2daf72454"}, "outputs": [], "execution_count": 6}, {"cell_type": "code", "source": "", "metadata": {"id": "3819ca9c-2359-4c9a-9213-4540b2f14cb9"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "41ca8d17-5eac-4abe-806a-2177b6124efe"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### 2. Convert HTML to text", "metadata": {"id": "61503760-de1a-469c-aba1-e1b26581dc79"}}, {"cell_type": "code", "source": "HTMLToText( [ file_names_arr[12] ], True )", "metadata": {"id": "bfaa0be0-111b-4d57-8628-76adc67c5f52"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "a1811e5a-a19d-434f-9590-61e3e6711cbb"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "28dd525e-c70b-42b4-a15e-5699176749ec"}, "outputs": [], "execution_count": null}]}