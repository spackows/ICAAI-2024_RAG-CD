{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Content Design for RAG\nThis notebook is part of a collection of material related to content design principles for retrieval-augmented generation (RAG).\n\nYou can explore the complete collection here: [Content Design for RAG on GitHub](https://github.com/spackows/ICAAI-2024_RAG-CD/blob/main/README.md)", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "id": "f3eb7a55-ecbb-46f5-ab8d-abdb64087dcd"}}, {"cell_type": "markdown", "source": "## Answer Natural Questions\nThis notebook demonstrates how to improve results on a subset of the [Natural Questions](https://ai.google.com/research/NaturalQuestions) benchmark by rewriting knowledge base content.\n\n**Contents**\n1. Download source files\n2. Split articles into chunks\n3. Create search component\n4. Identify relevant chunks\n5. Prompt LLM to answer questions\n6. Evaluate results\n7. Compile all results\n8. Save results", "metadata": {"id": "34ba5ed4-ebee-47cd-adfd-4cbf3113bee5"}}, {"cell_type": "markdown", "source": "## 1. Download source files", "metadata": {"id": "fa1bacfe-4ea9-4b39-9c3c-f1e86665e385"}}, {"cell_type": "code", "source": "g_file_names_arr = [\n\"Abundance-of-elements-in-Earths-crust.org.txt\",\n\"Atmosphere-of-Earth.org.txt\",\n\"Axial-precession.org.txt\",\n\"Axial-tilt.org.txt\",\n\"Carbon-cycle.org.txt\",\n\"Carbon-dioxide-in-Earths-atmosphere.org.txt\",\n\"Continent.org.txt\",\n\"Crust-geology.org.txt\",\n\"Earth.org.txt\",\n\"Earths-energy-budget.org.txt\",\n\"Earths-internal-heat-budget.org.txt\",\n\"Earths-magnetic-field.org.txt\",\n\"Earths-orbit.org.txt\",\n\"Earths-rotation.org.txt\",\n\"Inner-core.org.txt\",\n\"Mantle-geology.org.txt\",\n\"Mantle-convection.org.txt\",\n\"Plate-tectonics.org.txt\",\n\"Structure-of-the-Earth.org.txt\"\n]", "metadata": {"id": "62a0d120-f962-4a55-9a8d-6c713d611bd8"}, "outputs": [], "execution_count": 1}, {"cell_type": "code", "source": "g_base_url = \"https://raw.githubusercontent.com/spackows/ICAAI-2024_RAG-CD/main/Natural-Questions/\"", "metadata": {"id": "fd9df2b8-9ef3-4362-8d1a-78a796931e13"}, "outputs": [], "execution_count": 2}, {"cell_type": "code", "source": "!pip install wget | tail -n 1", "metadata": {"id": "e45d6a2b-021b-4ea2-8526-4a8669d0843f"}, "outputs": [{"name": "stdout", "text": "Successfully installed wget-3.2\n", "output_type": "stream"}], "execution_count": 3}, {"cell_type": "code", "source": "import os\nimport wget\n\ng_qa_file_name = \"questions-and-answers.jsonl\"\nurl = g_base_url + g_qa_file_name\nif not os.path.isfile( g_qa_file_name ):\n    wget.download( url, out = g_qa_file_name )", "metadata": {"id": "69912cc4-6490-4766-ab38-e73b324bd177"}, "outputs": [], "execution_count": 4}, {"cell_type": "code", "source": "!mkdir txt_org\n#!mkdir txt_updated", "metadata": {"id": "d543993c-8005-4524-af2e-a70704da5567"}, "outputs": [], "execution_count": 5}, {"cell_type": "code", "source": "import re\n\nfor file_name in g_file_names_arr:\n    full_file_name = \"txt_org/\" + file_name\n    #full_file_name = \"txt_updated/\" + re.sub( r\"\\.org\", \".updated\", file_name )\n    url = g_base_url + full_file_name\n    if not os.path.isfile( full_file_name ):\n        wget.download( url, out = full_file_name )", "metadata": {"id": "0d781679-ac55-49dc-b1be-4838f6e8b9bd"}, "outputs": [], "execution_count": 6}, {"cell_type": "code", "source": "!ls", "metadata": {"id": "74004e0f-1428-47a1-97b7-c6a5f1a95f00"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "!ls txt_org\n#!ls txt_updated", "metadata": {"id": "d9e2137e-0fce-493d-bf32-c95941efe9fd"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "33c0fe57-9455-4e51-8cdc-155c3ba8b8a0"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "746da24f-b7e6-4000-94f9-016bf8d370da"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 2. Split articles into chunks", "metadata": {"id": "e95d517f-5316-41c3-9fff-27425490ff71"}}, {"cell_type": "code", "source": "!pip install langchain_community | tail -n 1", "metadata": {"id": "a6cc4705-4b9a-4f21-8b4b-5ddb92893922"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "!pip install langchain_text_splitters | tail -n 1", "metadata": {"id": "8461365a-a53e-4bd6-b0b7-b6d4cd5f4044"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "!pip install unstructured | tail -n 1", "metadata": {"id": "2a0d4109-2741-4e66-83cf-617a5a7580e3"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from langchain_community.document_loaders import DirectoryLoader\n\ntxt_dir_name = \"txt_org\"\n#txt_dir_name = \"txt_updated\"\ntxt_loader = DirectoryLoader( txt_dir_name )\ng_txt_docs_arr = txt_loader.load()", "metadata": {"id": "48cac9f5-6d16-48b4-b0e8-5407737f932c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from langchain_text_splitters import MarkdownHeaderTextSplitter\n\ng_text_splitter_md = MarkdownHeaderTextSplitter( [ ( \"#\", \"Header 1\" ), ( \"##\", \"Header 2\" ), ( \"###\", \"Header 3\" ), ( \"####\", \"Header 4\" ) ], strip_headers=False )", "metadata": {"id": "c0c6309d-968f-46ae-aedb-978a04bee942"}, "outputs": [], "execution_count": 13}, {"cell_type": "code", "source": "g_txt_chunks = []\n\nfor doc in g_txt_docs_arr:\n    chunks = g_text_splitter_md.split_text( doc.page_content )\n    for chunk in chunks:\n        chunk.metadata[\"source\"] = doc.metadata[\"source\"]\n    g_txt_chunks.extend( chunks )", "metadata": {"id": "ab651540-5e58-4c1e-820b-c670dfada91c"}, "outputs": [], "execution_count": 14}, {"cell_type": "code", "source": "print( g_txt_chunks[0] )", "metadata": {"id": "fe5bc787-6477-4762-82bc-3ec46a34fef8"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "e7df1b94-a0eb-42d1-b845-31c75889092b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "0deac854-4d9c-4a0f-a680-42a6fa5acf27"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 3. Create search component\n\nhttps://python.langchain.com/v0.1/docs/integrations/vectorstores/chroma", "metadata": {"id": "729f127d-30d0-4232-b021-ee7020b1e5a6"}}, {"cell_type": "code", "source": "!pip install langchain_chroma | tail -n 1", "metadata": {"id": "9f71e30e-bc15-4da7-a5c7-b4ed96b7bf21"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "import re\nimport chromadb\nfrom langchain_chroma import Chroma\n\ndef createDocsMetadata( chunks ):\n    ids_arr = []\n    txt_arr = []\n    metadata_arr = []\n    current_source = \"\"\n    chunk_counter = 0\n    for chunk in chunks:\n        txt = chunk.page_content\n        source = chunk.metadata[\"source\"]\n        title = re.sub( r\"^.*\\/\", \"\", source )\n        title = re.sub( r\"\\..*$\", \"\", title )\n        title = re.sub( r\"^Earths\\-\", \"Earth's-\", title )\n        title = re.sub( r\"\\-geology\\-\", \"-(geology)-\", title )\n        title = re.sub( r\"\\-\", \" \", title )\n        if( source != current_source ):\n            current_source = source\n            chunk_counter = 0\n        num_str = str( chunk_counter )\n        if( chunk_counter < 10 ):\n            num_str = \"0\" + num_str\n        id = source + \"_\" + num_str\n        ids_arr.append( id )\n        txt_arr.append( txt )\n        metadata_arr.append( { \"source\" : source, \"chunk_num\" : num_str, \"title\" : title } )\n        chunk_counter += 1\n    return ids_arr, txt_arr, metadata_arr\n\ndef createMDSimilarityRetriever( chunks_arr, chroma_client, collection_name ):\n    ids_arr, txt_arr, metadata_arr = createDocsMetadata( chunks_arr )\n    collection = chroma_client.create_collection( collection_name )\n    collection.add( ids=ids_arr, documents=txt_arr, metadatas = metadata_arr )\n    return collection", "metadata": {"id": "067838fa-4a9f-4d94-888e-d468f4302be1"}, "outputs": [], "execution_count": 31}, {"cell_type": "code", "source": "g_chroma_client = chromadb.Client()", "metadata": {"id": "2849a5fa-5fe2-4ab7-9d4d-d53872c35358"}, "outputs": [], "execution_count": 32}, {"cell_type": "code", "source": "collection_name = \"txt_md_collection\"\n\ng_txt_md_similarity_db = createMDSimilarityRetriever( g_txt_chunks, g_chroma_client, collection_name )", "metadata": {"id": "3f6dde9e-fdda-4fd2-9c33-ddb6e670ac67"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "6760c55d-d937-466d-ad17-214e74432a32"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "423eaa95-ccc4-4dad-8db4-9cdd56a8012d"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 4. Identify relevant chunks", "metadata": {"id": "61dac86e-23f9-4b53-a79f-05cebfda9687"}}, {"cell_type": "markdown", "source": "### 4.1 Read questions", "metadata": {"id": "a7af2f79-75e2-4ebc-b690-6d56d6d52365"}}, {"cell_type": "code", "source": "import json\n\ndef readQuestionsAndAnswers( file_name ):\n    f = open( file_name, \"r\" )\n    content = f.read()\n    f.close()\n    questions_json = {}\n    lines_arr = content.splitlines()\n    for line in lines_arr:\n        json_line = json.loads( line )\n        example_id = json_line[\"example_id\"]\n        question_txt = json_line[\"question_txt\"]\n        answers_arr = json_line[\"answers_arr\"]\n        article_title = json_line[\"article_title\"]\n        questions_json[ example_id ] = { \"question\" : question_txt, \n                                         \"expected_article_title\" : article_title, \n                                         \"expected_answers_arr\"   : answers_arr }\n    return questions_json", "metadata": {"id": "a6a4c8e8-6c0c-4a8b-9df6-e0550f08a203"}, "outputs": [], "execution_count": 20}, {"cell_type": "code", "source": "g_qa_json = readQuestionsAndAnswers( g_qa_file_name )", "metadata": {"id": "ba6748cb-c1fc-4faa-b26d-3ba7332c7d1f"}, "outputs": [], "execution_count": 21}, {"cell_type": "code", "source": "example_id = list( g_qa_json.keys() )[0]\n\nprint( \"example_id: \" + example_id + \"\\n\" )\nprint( json.dumps( g_qa_json[ example_id ], indent=3 ) )", "metadata": {"id": "b3871f16-647a-407a-9351-33e6fe3c7005"}, "outputs": [{"name": "stdout", "text": "example_id: -1368633715963532113\n\n{\n   \"question\": \"where can carbon be found in the biosphere\",\n   \"expected_article_title\": \"Carbon cycle\",\n   \"expected_answers_arr\": [\n      \"in all land - living organisms , both alive and dead , as well as carbon stored in soils\",\n      \"in all land - living organisms , both alive and dead , as well as carbon stored in soils\",\n      \"plants other living organisms soil\",\n      \"The terrestrial biosphere\"\n   ]\n}\n", "output_type": "stream"}], "execution_count": 23}, {"cell_type": "markdown", "source": "### 4.2 Find relevant chunks for each question", "metadata": {"id": "b875cdd6-1fe6-47f3-a5f3-25401355dbb9"}}, {"cell_type": "code", "source": "def searchArticles( question_txt ):\n\n    search_results = []\n    \n    raw_search_results = g_txt_md_similarity_db.query( query_texts = [ question_txt ], n_results = 2 )\n    \n    num_results = len( raw_search_results[\"distances\"][0] ) if ( ( \"distances\" in raw_search_results ) and ( len( raw_search_results[\"distances\"] ) > 0 ) ) else 0\n    \n    for i in range( num_results ):\n\n        score     = raw_search_results[\"distances\"][0][i]\n        file_name = raw_search_results[\"metadatas\"][0][i][\"source\"]\n        chunk_num = raw_search_results[\"metadatas\"][0][i][\"chunk_num\"]\n        title     = raw_search_results[\"metadatas\"][0][i][\"title\"]\n        txt       = raw_search_results[\"documents\"][0][i]\n        \n        search_results.append( { \"search_diff\" : round( 100 * score ) / 100, \n                                 \"file_name\"   : file_name,\n                                 \"chunk_num\"   : chunk_num,\n                                 \"title\"       : title,\n                                 \"chunk\"       : txt } )\n    \n    return search_results", "metadata": {"id": "09a170c9-5615-4050-ba71-e7ec0b429091"}, "outputs": [], "execution_count": 24}, {"cell_type": "code", "source": "g_txt_md_similarity_db.query( query_texts = [ \"what is found in the earth's crust\" ], n_results = 2 )", "metadata": {"id": "5218ab7f-168b-42ae-864b-fb41dc93cb3d"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "def findRelevantChunks( qa_json ):\n    relevant_chunks = {}\n    example_ids_arr = qa_json.keys()\n    for example_id in example_ids_arr:\n        question_json = g_qa_json[ example_id ]\n        question_txt = question_json[\"question\"]\n        relevant_chunks[ example_id ] = searchArticles( question_txt )\n    return relevant_chunks", "metadata": {"id": "d1e335dd-9886-481a-8df7-02536ae4ed0b"}, "outputs": [], "execution_count": 26}, {"cell_type": "code", "source": "g_relevant_chunks = findRelevantChunks( g_qa_json )", "metadata": {"id": "b2e4a71b-c379-4250-acf5-19a1f47e43ec"}, "outputs": [], "execution_count": 27}, {"cell_type": "code", "source": "example_id = list( g_qa_json.keys() )[0]\n\nprint( \"example_id: \" + example_id + \"\\n\" )\nprint( json.dumps( g_relevant_chunks[ example_id ], indent=3 ) )", "metadata": {"id": "c4ee91cd-d632-45ce-b8d3-07cad808df6d"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "64cb9ef7-b9c0-41f8-8062-033bc459e38c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "9602f370-b224-4382-a7a1-274b0fc1ebae"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 5. Prompt LLM to answer\n\nSee: [Foundation models Python library](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html)\n\n### Prerequisites\nBefore you can prompt a foundation model in watsonx.ai, you must perform the following setup tasks:\n- 5.1 Create an instance of the Watson Machine Learning service\n- 5.2 Associate the Watson Machine Learning instance with the current project\n- 5.3 Create an IBM Cloud API key\n- 5.4 Look up the current project ID", "metadata": {"id": "9f0d1759-8451-4c46-b028-c7ae66b1ba97"}}, {"cell_type": "markdown", "source": "#### 5.1 Create an instance of the Watson Machine Learning service\nIf you don't already have an instance of the IBM Watson Machine Learning service, you can create an instance of the service from the IBM Cloud catalog: [Watson Machine Learning service](https://cloud.ibm.com/catalog/services/watson-machine-learning)", "metadata": {"id": "b9c7d32d-6e26-4117-a466-57b6864ad56b"}}, {"cell_type": "markdown", "source": "#### 5.2 Associate an instance of the Watson Machine Learning service with the current project\nThe current project is the project in which you are running this notebook.\n\nIf an instance of Watson Machine Learning is not already associated with the current project, follow the instructions in this topic to do so: [Adding associated services to a project](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html?context=wx&audience=wdp)", "metadata": {"id": "3a574dfa-4263-435a-8b09-06c69af82f25"}}, {"cell_type": "markdown", "source": "#### 5.3 Create an IBM Cloud API key\nCreate an IBM Cloud API key by following these instruction: [Creating an IBM Cloud API key](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key)\n\nThen paste your new IBM Cloud API key in the code cell below.", "metadata": {"id": "91a2226f-529c-4bd2-af0d-1e17d60fec27"}}, {"cell_type": "code", "source": "cloud_apikey = \"\"\n\ng_wml_credentials = { \n    \"url\"    : \"https://us-south.ml.cloud.ibm.com\", \n    \"apikey\" : cloud_apikey\n}", "metadata": {"id": "bd731b5c-4057-436a-a374-f37cbbdaa6cc"}, "outputs": [], "execution_count": 34}, {"cell_type": "markdown", "source": "#### 5.4 Look up the current project ID\nThe current project is the project in which you are running this notebook. You can get the ID of the current project programmatically by running the following cell.", "metadata": {"id": "83de5124-9259-477b-a1ab-845061b27351"}}, {"cell_type": "code", "source": "import os\n\ng_project_id = os.environ[\"PROJECT_ID\"]", "metadata": {"id": "d2e6f67b-1b63-4d61-a86b-0f2529c8cd3b"}, "outputs": [], "execution_count": 35}, {"cell_type": "markdown", "source": "Now prompt a model to answer the questions ...", "metadata": {"id": "3976e437-b8f4-44f3-8278-7e2146a18eb1"}}, {"cell_type": "code", "source": "g_prompt_template = \"\"\"\nArticle:\n###\n%s\n###\n\nAnswer the following question using only information from the article. \nAnswer in a complete sentence, with proper capitalization and punctuation. \nIf there is no good answer in the article, say \"I don't know\".\n\nQuestion: %s\nAnswer: \n\"\"\"", "metadata": {"id": "f5c8f8c1-6552-412f-bcf4-90d03478cf85"}, "outputs": [], "execution_count": 36}, {"cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\n\ng_model_id = \"google/flan-t5-xxl\"\n\ng_prompt_parameters = {\n    \"decoding_method\" : \"greedy\",\n    \"min_new_tokens\"  : 0,\n    \"max_new_tokens\"  : 300\n}\n\ng_model = Model( g_model_id, g_wml_credentials, g_prompt_parameters, g_project_id )", "metadata": {"id": "076bb9ba-0d7d-4c6b-9a57-ffea6539fab8"}, "outputs": [], "execution_count": 37}, {"cell_type": "code", "source": "import math\nimport re\n\ndef countTokens( chunk_txt, model ):\n    tokenized_response = model.tokenize( chunk_txt )\n    return tokenized_response[\"result\"][\"token_count\"]\n\ndef chopTxt( chunk_txt_org, model, max_tokens ):\n    num_words = len( chunk_txt_org.split() )\n    num_tokens = countTokens( chunk_txt_org, model )\n    max_words = math.floor( max_tokens * num_words / num_tokens )\n    chunk_txt = re.sub( r\"\\n\", \" __NEWLINE__ \", chunk_txt_org )\n    num_prompt_template_words = 50\n    chopped_txt = \" \".join( chunk_txt.split()[ 0 : ( max_words - num_prompt_template_words ) ] )\n    chopped_txt = re.sub( r\"__NEWLINE__\", \"\\n\", chopped_txt )\n    num_tokens = countTokens( chopped_txt, model )\n    safety = 75\n    while( ( num_tokens + safety ) > max_tokens ):\n        max_words = max_words - 50\n        chopped_txt = \" \".join( chunk_txt.split()[ 0 : ( max_words - num_prompt_template_words ) ] )\n        chopped_txt = re.sub( r\"__NEWLINE__\", \"\\n\", chopped_txt )\n        num_tokens = countTokens( chopped_txt, model )\n    print( \"num_tokens: \" + str( num_tokens ) )\n    return chopped_txt", "metadata": {"id": "84822df6-1839-45a5-85d1-a7c75c593a8f"}, "outputs": [], "execution_count": 38}, {"cell_type": "code", "source": "def answerQuestion( chunk_txt, question_txt, b_debug=False ):\n    chunk_txt = chopTxt( chunk_txt, g_model, 4000 )\n    prompt_text = g_prompt_template % ( chunk_txt, question_txt )\n    raw_response = g_model.generate( prompt_text )\n    if b_debug:\n        print( \"prompt_text:\\n'\" + prompt_text + \"'\\n\" )\n        print( \"raw_response:\\n\" + json.dumps( raw_response, indent=3 ) )\n    if ( \"results\" in raw_response ) \\\n       and ( len( raw_response[\"results\"] ) > 0 ) \\\n       and ( \"generated_text\" in raw_response[\"results\"][0] ):\n        output = raw_response[\"results\"][0][\"generated_text\"]\n        return output\n    else:\n        return \"\"", "metadata": {"id": "3681e889-8363-4a38-9ba0-6253cee94ed2"}, "outputs": [], "execution_count": 39}, {"cell_type": "code", "source": "def answerQuestions( qa_json, relevant_chunks, b_debug=False ):\n    generated_answers = {}\n    example_ids_arr = qa_json.keys()\n    for example_id in example_ids_arr:\n        chunk_txt = relevant_chunks[ example_id ][0][\"chunk\"] + \"\\n\\n\" + relevant_chunks[ example_id ][1][\"chunk\"]\n        question_txt = qa_json[ example_id ][\"question\"]\n        answer_txt = answerQuestion( chunk_txt, question_txt, b_debug )\n        generated_answers[ example_id ] = answer_txt\n    return generated_answers", "metadata": {"id": "85003280-94ad-4b65-9c48-7e2502a4f021"}, "outputs": [], "execution_count": 40}, {"cell_type": "code", "source": "g_generated_answers = answerQuestions( g_qa_json, g_relevant_chunks, True )", "metadata": {"id": "11cf1abe-ddfa-4ef4-a62e-df45398531d6"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "print( json.dumps( g_generated_answers, indent=3 ) )", "metadata": {"id": "31e98e10-0d7f-49fd-b0c8-c77779b2199e"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "fb00e052-b749-4d55-88cf-6bf8f91c23da"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "f6b1f541-f011-45f5-98d8-8205026fcaad"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 6. Evaluate results", "metadata": {"id": "31661333-f01d-46a1-9c30-f12e02eb7c2b"}}, {"cell_type": "code", "source": "!pip install sentence-transformers | tail -n 1", "metadata": {"id": "570f32bc-5a17-48ff-819a-111a50136980"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from sentence_transformers import SentenceTransformer, util", "metadata": {"id": "727c7c33-d98e-47b1-88fa-51bdb5fc354e"}, "outputs": [], "execution_count": 44}, {"cell_type": "code", "source": "import numpy as np\n\nst_model = SentenceTransformer( \"all-MiniLM-L6-v2\" )\n\ndef sentenceTransformerScore( txt1, txt2 ):\n    txt1_embeddings  = st_model.encode( [ txt1 ],  convert_to_tensor=True )\n    txt2_embeddings = st_model.encode( [ txt2 ], convert_to_tensor=True )\n    cosine_scores = util.cos_sim( txt1_embeddings, txt2_embeddings )\n    sentence_transformers_score_arr = [ round( float( x ), 2 ) for x in cosine_scores[0] ]\n    score = int( 100*sentence_transformers_score_arr[0] )\n    return score", "metadata": {"id": "91fa1254-2de2-4a8b-93d7-8e8aca0a2220"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "def compareAnswers( expected_answers, run_time_answer ):\n    high_score = 0\n    for answer_txt in expected_answers:\n        score = sentenceTransformerScore( answer_txt, run_time_answer )\n        if( score > high_score ):\n            high_score = score\n    return high_score", "metadata": {"id": "f8518839-38d9-450e-9a88-0441879a6137"}, "outputs": [], "execution_count": 46}, {"cell_type": "code", "source": "def evaluateAnswers( qa_json, generated_answers ):\n    eval_json = {}\n    example_ids_arr = qa_json.keys()\n    for example_id in example_ids_arr:\n        expected_answers = qa_json[ example_id ][\"expected_answers_arr\"]\n        run_time_answer = generated_answers[ example_id ]\n        highest_score = compareAnswers( expected_answers, run_time_answer )\n        eval_json[ example_id ] = highest_score\n    return eval_json", "metadata": {"id": "44a56aa3-bd62-47d6-a140-f2388906d736"}, "outputs": [], "execution_count": 49}, {"cell_type": "code", "source": "g_eval_json = evaluateAnswers( g_qa_json, g_generated_answers )", "metadata": {"id": "4461a80b-1f7a-48b3-bf52-ec31cb1ce264"}, "outputs": [], "execution_count": 50}, {"cell_type": "code", "source": "print( json.dumps( g_eval_json, indent=3 ) )", "metadata": {"id": "1f252cc6-623d-499e-88a5-35c4a56fc15d"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "81582caf-cc86-4654-9c08-ae3505483140"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "7c713634-9610-4b0a-b3aa-1494e068e8a6"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 7. Compile all results", "metadata": {"id": "7f6a7e63-b07a-4689-9507-751907bbfefc"}}, {"cell_type": "code", "source": "g_results = []\nfor example_id in g_qa_json:\n    question = g_qa_json[ example_id ][\"question\"]\n    expected_answers_arr = g_qa_json[ example_id ][\"expected_answers_arr\"]\n    expected_article = g_qa_json[ example_id ][\"expected_article_title\"]\n    relevant_article = g_relevant_chunks[ example_id ][0][\"title\"]\n    relevant_chunk = g_relevant_chunks[ example_id ][0][\"chunk\"]\n    run_time_answer = g_generated_answers[ example_id ]\n    score = g_eval_json[ example_id ]\n    g_results.append( { \"example_id\" : \"'\" + str( example_id ),\n                        \"Expected article\" : expected_article,\n                        \"Relevant article\" : relevant_article,\n                        \"Chunk\" : relevant_chunk,\n                        \"Question\" : question,\n                        \"Expected answers\" : \"- \" + \"\\n- \".join( expected_answers_arr ),\n                        \"Run-time answer\" : run_time_answer,  \n                        \"Score\" : score } )\ng_results = sorted( g_results, key=lambda d: d[\"Score\"] )\nprint( json.dumps( g_results[0], indent=3 ) )", "metadata": {"id": "2e49e86b-7669-49b0-bc48-e7d1368f4104"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "import pandas as pd\n\ndf = pd.DataFrame( g_results )\ndf", "metadata": {"id": "4669fa4d-c678-4ff7-8a42-b71f554dd160"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "656adab6-8580-419e-bea8-67b827928908"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "01555123-06ee-4992-a56e-fb5091088385"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 8. Save results\n**Note:** To use wslib to save results to your project, you must add a project token.\n\nSee: [ibm-watson-studio-lib for Python](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ws-lib-python.html?context=wx&audience=wdp)", "metadata": {"id": "afbdb1ea-fdb7-4741-956e-605c494e92df"}}, {"cell_type": "code", "source": "", "metadata": {"id": "8fd18fea-a702-440d-8cf4-d3c809185ecf"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "wslib.save_data( \"results.csv\", df.to_csv( index=False ).encode() )", "metadata": {"id": "72bc0363-3049-4554-8963-af817cd397f8"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "c42db912-4095-4042-826f-4db7f62f2676"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "a78fffe8-cde4-43ac-8f06-72a53e440d8d"}, "outputs": [], "execution_count": null}]}
